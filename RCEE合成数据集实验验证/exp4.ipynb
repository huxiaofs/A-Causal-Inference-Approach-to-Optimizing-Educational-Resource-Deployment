{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到了这个版本，已经把ACE和找最简的后门路径调整集这两步都已经完成了。下一步要做的：\n",
    "1. 确认生成数据的细节\n",
    "2. 更改循环方式，确保生成的每一张图都有非0的ACE\n",
    "3. 然后用数据验证RCEE\n",
    "4. 定义几个指标：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from random import choice, randint, uniform\n",
    "from itertools import chain\n",
    "from statsmodels.formula.api import logit\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 识别后门调整集\n",
    "def find_backdoor_adjustment_set(G, X, Y):\n",
    "    # 找到所有共同祖先节点\n",
    "    ancestors_of_X = nx.ancestors(G, X)\n",
    "    ancestors_of_Y = nx.ancestors(G, Y)\n",
    "    common_ancestors = ancestors_of_X.intersection(ancestors_of_Y)\n",
    "        \n",
    "    # 存储所有后门路径的节点集合\n",
    "    backdoor_paths_nodes = []\n",
    "\n",
    "    # 遍历每个共同祖先节点\n",
    "    for ancestor in common_ancestors:\n",
    "        # 找到从公共祖先到X的路径\n",
    "        paths_to_X = list(nx.all_simple_paths(G, source=ancestor, target=X))\n",
    "        # 找到从公共祖先到Y的路径\n",
    "        paths_to_Y = list(nx.all_simple_paths(G, source=ancestor, target=Y))\n",
    "\n",
    "        # 将从公共祖先到X的路径和从公共祖先到Y的路径组合成完整的后门路径\n",
    "        for path_X in paths_to_X:\n",
    "            for path_Y in paths_to_Y:\n",
    "            # 从路径中去掉公共祖先和终点X、Y，防止重复\n",
    "                full_path = set(path_X[:-1] + path_Y[1:-1])\n",
    "                # 添加路径到后门路径集合\n",
    "                if full_path:\n",
    "                    backdoor_paths_nodes.append(full_path)\n",
    "        \n",
    "    # 找到覆盖所有路径的最小集合\n",
    "    return minimum_cover(backdoor_paths_nodes)\n",
    "\n",
    "# 求最小覆盖集\n",
    "def minimum_cover(sets):\n",
    "    # 展开集合中的所有元素\n",
    "    elements = set(chain(*sets))\n",
    "    cover = set()\n",
    "    \n",
    "    while sets:\n",
    "        # 找到最常出现的元素\n",
    "        most_common = max(elements, key=lambda e: sum(1 for s in sets if e in s))\n",
    "        cover.add(most_common)\n",
    "            \n",
    "        # 移除包含该元素的所有集合\n",
    "        sets = [s for s in sets if most_common not in s]\n",
    "        elements.discard(most_common)\n",
    "        \n",
    "    return list(cover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算从干预变量到结果变量的总体因果效应（ACE）\n",
    "def calculate_ace(G, adj_matrix, X, Y):\n",
    "    paths = list(nx.all_simple_paths(G, source=X, target=Y))\n",
    "    ace = 0\n",
    "    for path in paths:\n",
    "        # 串联：每条路径上的系数相乘\n",
    "        path_weight = np.prod([adj_matrix[path[i], path[i+1]] for i in range(len(path) - 1)])\n",
    "        # 并联：每条路径的效应相加\n",
    "        ace += path_weight\n",
    "    return ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DAG 0 Adjacency Matrix with Weights:\n",
      " [[0.         0.         0.         0.23891407 0.         0.13522723\n",
      "  0.9528282  0.         0.         0.38467517]\n",
      " [0.         0.         0.61022704 0.         0.         0.57480442\n",
      "  0.81695265 0.97543744 0.14806087 0.37138077]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.39286811 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.51275003 0.89131733 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.5570435  0.42649433 0.9698469  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.34375191]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Backdoor Adjustment Set for DAG 0 from 1 to 6: []\n",
      "ACE for DAG 0 from 1 to 6: 1.137143713539559\n"
     ]
    }
   ],
   "source": [
    "# 参数定义\n",
    "num_dags = 1  # DAG数量\n",
    "num_nodes_range = (5, 15)  # 每个DAG节点数量范围\n",
    "# sample_sizes = [100, 200, 500]  # 数据集规模\n",
    "sample_sizes = [100000]\n",
    "noise_levels = [0.1, 0.5, 1.0]  # 噪声强度\n",
    "# noise_levels = [0]\n",
    "\n",
    "# 存储结果\n",
    "dag_data = []\n",
    "\n",
    "# 生成随机DAG，满足马尔可夫条件和忠实性\n",
    "for i in range(num_dags):\n",
    "    # 生成随机节点数量的DAG\n",
    "    num_nodes = randint(*num_nodes_range)\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(range(num_nodes))\n",
    "    \n",
    "    # 创建邻接矩阵，并随机生成有向边\n",
    "    adj_matrix = np.zeros((num_nodes, num_nodes))\n",
    "    for u in range(num_nodes):\n",
    "        for v in range(u + 1, num_nodes):\n",
    "            if np.random.rand() > 0.7:  # 30%几率添加边\n",
    "                weight = uniform(0.1, 1.0)\n",
    "                adj_matrix[u, v] = weight\n",
    "                G.add_edge(u, v, weight=weight)\n",
    "\n",
    "    # 打印邻接矩阵\n",
    "    print(f\"\\nDAG {i} Adjacency Matrix with Weights:\\n\", adj_matrix)\n",
    "\n",
    "    # 选择干预和结果变量\n",
    "    intervention_var = choice(list(G.nodes))\n",
    "    outcome_var = choice([n for n in G.nodes if n != intervention_var])\n",
    "\n",
    "    # 识别后门调整集\n",
    "    backdoor_set = find_backdoor_adjustment_set(G, intervention_var, outcome_var)\n",
    "    print(f\"Backdoor Adjustment Set for DAG {i} from {intervention_var} to {outcome_var}:\", backdoor_set)\n",
    "\n",
    "    # 计算从干预变量到结果变量的总体因果效应（ACE）\n",
    "    ace = calculate_ace(G, adj_matrix, intervention_var, outcome_var)\n",
    "    print(f\"ACE for DAG {i} from {intervention_var} to {outcome_var}:\", ace)\n",
    "\n",
    "    # 生成不同规模的数据及噪声\n",
    "    for sample_size in sample_sizes:\n",
    "        for noise_level in noise_levels:\n",
    "            data = np.zeros((sample_size, num_nodes))\n",
    "            for t in range(sample_size):\n",
    "                # 为拓扑排序中没有父节点的节点添加初始值，初始值为[-10, 10]之间的随机数\n",
    "                # print(\"拓扑排序：\", list(nx.topological_sort(G)))\n",
    "                for node in nx.topological_sort(G):\n",
    "                    # print(node, G.predecessors(node))\n",
    "                    if not list(G.predecessors(node)):\n",
    "                        data[t, node] = np.random.uniform(-10, 10) \n",
    "                # print(\"data:\", data)\n",
    "                # 初始化根节点的值\n",
    "                for node in nx.topological_sort(G): # 拓扑排序\n",
    "                    if list(G.predecessors(node)):\n",
    "                        noise = np.random.normal(0, noise_level) # 添加高斯噪声\n",
    "                        parent_values = sum(adj_matrix[parent, node] * data[t, parent] for parent in G.predecessors(node))\n",
    "                        data[t, node] = parent_values + noise\n",
    "            # print(\"data:\", data)\n",
    "            # 存储DAG数据及因果效应\n",
    "            dag_data.append({\n",
    "                'dag_id': i,\n",
    "                'sample_size': sample_size,\n",
    "                'noise_level': noise_level,\n",
    "                'weight_matrix': adj_matrix,\n",
    "                'intervention_var': intervention_var,\n",
    "                'outcome_var': outcome_var,\n",
    "                'backdoor_set': backdoor_set,\n",
    "                'ace': ace,\n",
    "                'data': pd.DataFrame(data, columns=[f'X{j}' for j in range(num_nodes)]),\n",
    "                'estimated_ace': None,\n",
    "                'lower_bound_of_confidence_interval': None,\n",
    "                'upper_bound_of_confidence_interval': None\n",
    "            })\n",
    "            # print(f\"Data for DAG {i} with {sample_size} samples and noise level {noise_level}:\\n\", dag_data[-1]['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAG ID: 0\n",
      "Sample Size: 100000\n",
      "Noise Level: 0.1\n",
      "Intervention Variable: 1\n",
      "Outcome Variable: 6\n",
      "Backdoor Adjustment Set: []\n",
      "ACE (Total Effect): 1.137143713539559\n",
      "Sample Data:\n",
      "          X0        X1        X2        X3        X4        X5         X6  \\\n",
      "0  9.775649  7.606990  4.528001  2.396490  4.175005  5.648451  18.487992   \n",
      "1  0.255306  9.046579  5.379245  0.044222  8.072053  5.193767  10.502860   \n",
      "2 -6.208228 -1.770173 -1.265993 -1.350799  1.397919 -1.784887  -8.395440   \n",
      "3 -8.336175  5.453811  3.355196 -1.826548  5.149575  2.038419  -2.404294   \n",
      "4  2.599526 -6.087847 -3.497500  0.555092  5.034781 -3.087120  -4.143839   \n",
      "\n",
      "          X7         X8         X9  \n",
      "0  13.698442  10.297077  11.358580  \n",
      "1  17.042905  13.548670   9.204909  \n",
      "2  -2.311982  -0.876596  -3.679033  \n",
      "3  10.164900   7.524098   2.222232  \n",
      "4  -6.069728   0.517437  -3.275462  \n"
     ]
    }
   ],
   "source": [
    "# 示例：打印生成的第一个DAG的结果\n",
    "example_dag = dag_data[0]\n",
    "print(\"DAG ID:\", example_dag['dag_id'])\n",
    "print(\"Sample Size:\", example_dag['sample_size'])\n",
    "print(\"Noise Level:\", example_dag['noise_level'])\n",
    "print(\"Intervention Variable:\", example_dag['intervention_var'])\n",
    "print(\"Outcome Variable:\", example_dag['outcome_var'])\n",
    "print(\"Backdoor Adjustment Set:\", example_dag['backdoor_set'])\n",
    "print(\"ACE (Total Effect):\", example_dag['ace'])\n",
    "print(\"Sample Data:\\n\", example_dag['data'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check(data):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X6 ~ X1\n"
     ]
    }
   ],
   "source": [
    "if example_dag['backdoor_set']:\n",
    "    target = \"X\" + str(example_dag['outcome_var']) + \" ~ \" + \"X\" + str(example_dag['intervention_var']) + \" + \" + \" + \".join([f\"X{node}\" for node in example_dag['backdoor_set']])\n",
    "    print(target)\n",
    "else:\n",
    "    target = \"X\" + str(example_dag['outcome_var']) + \" ~ \" + \"X\" + str(example_dag['intervention_var'])\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if example_dag['backdoor_set']:\n",
    "# #     # 建立逻辑回归模型\n",
    "# #     model = logit(\"X\" + str(example_dag['outcome_var']) + \" ~ \" + \" + \".join([f\"X{node}\" for node in example_dag['backdoor_set']]), data=example_dag['data']).fit()\n",
    "\n",
    "# #     # 显示模型结果\n",
    "# #     print(model.summary())\n",
    "# # Normalize the outcome variable to be within the unit interval [0, 1]\n",
    "# # example_dag['data'][f\"X{example_dag['outcome_var']}\"] = (example_dag['data'][f\"X{example_dag['outcome_var']}\"] - example_dag['data'][f\"X{example_dag['outcome_var']}\"].min()) / (example_dag['data'][f\"X{example_dag['outcome_var']}\"].max() - example_dag['data'][f\"X{example_dag['outcome_var']}\"].min())\n",
    "\n",
    "\n",
    "\n",
    "# # 建立逻辑回归模型\n",
    "# model = logit(target, data=example_dag['data']).fit()\n",
    "    \n",
    "# # 显示模型结果\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated ACE: 1.1381110515755477\n",
      "[1.13811105]\n"
     ]
    }
   ],
   "source": [
    "# 自变量和因变量\n",
    "X_num = [example_dag['intervention_var']] + example_dag['backdoor_set']\n",
    "X = example_dag['data'][[f'X{j}' for j in X_num]]\n",
    "y_num = example_dag['outcome_var']\n",
    "y = example_dag['data'][f'X{y_num}']\n",
    "# print(X)\n",
    "# print(y)\n",
    "\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "# 计算因果效应\n",
    "ace = model.coef_[0]\n",
    "print(\"Estimated ACE:\", ace)\n",
    "\n",
    "# 存储估计的ACE\n",
    "example_dag['estimated_ace'] = ace\n",
    "\n",
    "# 打印model的系数\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     X6   R-squared:                       0.551\n",
      "Model:                            OLS   Adj. R-squared:                  0.551\n",
      "Method:                 Least Squares   F-statistic:                 1.227e+05\n",
      "Date:                Thu, 17 Oct 2024   Prob (F-statistic):               0.00\n",
      "Time:                        14:35:51   Log-Likelihood:            -3.1993e+05\n",
      "No. Observations:              100000   AIC:                         6.399e+05\n",
      "Df Residuals:                   99998   BIC:                         6.399e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.0082      0.019     -0.437      0.662      -0.045       0.029\n",
      "X1             1.1381      0.003    350.249      0.000       1.132       1.144\n",
      "==============================================================================\n",
      "Omnibus:                    84468.167   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5947.640\n",
      "Skew:                           0.003   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.805   Cond. No.                         5.77\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 建立线性回归模型\n",
    "model = ols(target, data=example_dag['data']).fit()\n",
    "    \n",
    "# 显示模型结果\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以再探讨一下置信区间的缩小速度，以及置信区间的大小与样本量的关系。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
